{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b386d156",
   "metadata": {},
   "source": [
    "# üöÄ Crack Detection - Complete Training Pipeline\n",
    "\n",
    "Questo notebook installa tutto automaticamente e esegue il training completo.\n",
    "\n",
    "**Basta eseguire le celle in sequenza!**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Cosa fa questo notebook:\n",
    "\n",
    "1. ‚úÖ Verifica ambiente (GPU, Python)\n",
    "2. ‚úÖ Installa tutte le dipendenze\n",
    "3. ‚úÖ Configura credenziali Kaggle\n",
    "4. ‚úÖ Scarica dataset (2.1 GB)\n",
    "5. ‚úÖ Training completo (50 epoche)\n",
    "6. ‚úÖ Inference + Evaluation\n",
    "\n",
    "**Durata totale: ~2-3 ore**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c466c8",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 1: Verifica Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0305f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica Python e GPU\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Verifica GPU\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\n‚úÖ PyTorch gi√† installato: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è PyTorch non ancora installato (verr√† installato dopo)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef20cc",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Installa Dipendenze\n",
    "\n",
    "**Questo installer√† automaticamente tutte le librerie necessarie:**\n",
    "- PyTorch (per GPU se disponibile)\n",
    "- OpenCV\n",
    "- Matplotlib, Pillow\n",
    "- Tensorboard, tqdm\n",
    "- Kaggle CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0786d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installa tutte le dipendenze\n",
    "!pip install --quiet --upgrade pip\n",
    "!pip install --quiet torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install --quiet opencv-python matplotlib Pillow tqdm tensorboard numpy kaggle\n",
    "\n",
    "print(\"‚úÖ Tutte le dipendenze installate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64891c39",
   "metadata": {},
   "source": [
    "## üì• Step 3: Clone Repository GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5483a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (o aggiorna se esiste)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_URL = \"https://github.com/Biobay/DeepLearningHard_ISWM.git\"\n",
    "PROJECT_DIR = Path(\"/content/DeepLearningHard_ISWM\")  # Per Google Colab\n",
    "# Per Jupyter locale: PROJECT_DIR = Path.home() / \"DeepLearningHard_ISWM\"\n",
    "\n",
    "if PROJECT_DIR.exists():\n",
    "    print(\"Repository gi√† esistente, pulling updates...\")\n",
    "    !cd {PROJECT_DIR} && git pull\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone {REPO_URL} {PROJECT_DIR}\n",
    "\n",
    "# Vai nella directory del progetto\n",
    "os.chdir(PROJECT_DIR)\n",
    "print(f\"\\n‚úÖ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e4b2c",
   "metadata": {},
   "source": [
    "## üîë Step 4: Configura Credenziali Kaggle\n",
    "\n",
    "**IMPORTANTE:** Sostituisci con le tue credenziali!\n",
    "\n",
    "Ottienile da: https://www.kaggle.com/settings ‚Üí API ‚Üí Create New Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è SOSTITUISCI CON LE TUE CREDENZIALI KAGGLE!\n",
    "KAGGLE_USERNAME = \"mariomastrulli\"  # ‚Üê Cambia con il tuo\n",
    "KAGGLE_KEY = \"KGAT_08037a2cf26b2f7ffa2612c5b6764b04\"   # ‚Üê Cambia con la tua\n",
    "\n",
    "# Setup credenziali\n",
    "import json\n",
    "kaggle_dir = Path.home() / \".kaggle\"\n",
    "kaggle_dir.mkdir(exist_ok=True)\n",
    "\n",
    "kaggle_config = {\n",
    "    \"username\": KAGGLE_USERNAME,\n",
    "    \"key\": KAGGLE_KEY\n",
    "}\n",
    "\n",
    "kaggle_file = kaggle_dir / \"kaggle.json\"\n",
    "with open(kaggle_file, 'w') as f:\n",
    "    json.dump(kaggle_config, f)\n",
    "\n",
    "# Set permissions\n",
    "os.chmod(kaggle_file, 0o600)\n",
    "\n",
    "print(\"‚úÖ Credenziali Kaggle configurate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b97a77e",
   "metadata": {},
   "source": [
    "## üì• Step 5: Scarica Dataset da Kaggle\n",
    "\n",
    "**Questo scaricher√† 2.1 GB - pu√≤ richiedere 5-10 minuti**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8cc9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scarica dataset da Kaggle\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "KAGGLE_DATASET = \"lakshaymiddha/crack-segmentation-dataset\"\n",
    "dataset_path = PROJECT_DIR / \"dataset\"\n",
    "train_images = dataset_path / \"train\" / \"images\"\n",
    "\n",
    "# Check se gi√† esiste\n",
    "if train_images.exists() and list(train_images.glob(\"*.jpg\")):\n",
    "    print(f\"‚úÖ Dataset gi√† presente ({len(list(train_images.glob('*.jpg')))} immagini)\")\n",
    "else:\n",
    "    print(\"üì• Downloading dataset da Kaggle (2.1 GB)...\")\n",
    "    !kaggle datasets download -d {KAGGLE_DATASET}\n",
    "    \n",
    "    # Trova zip\n",
    "    zip_file = list(PROJECT_DIR.glob(\"*.zip\"))[0]\n",
    "    print(f\"üì¶ Extracting {zip_file.name}...\")\n",
    "    \n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(PROJECT_DIR)\n",
    "    \n",
    "    zip_file.unlink()\n",
    "    \n",
    "    # Organizza struttura\n",
    "    print(\"üìÅ Organizing dataset structure...\")\n",
    "    dataset_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    mappings = {\n",
    "        'train_images': dataset_path / 'train' / 'images',\n",
    "        'train_masks': dataset_path / 'train' / 'masks',\n",
    "        'test_images': dataset_path / 'test' / 'images',\n",
    "        'test_masks': dataset_path / 'test' / 'masks',\n",
    "    }\n",
    "    \n",
    "    for src_name, dest_path in mappings.items():\n",
    "        src_path = PROJECT_DIR / src_name\n",
    "        if src_path.exists():\n",
    "            dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.move(str(src_path), str(dest_path))\n",
    "    \n",
    "    print(\"‚úÖ Dataset scaricato e organizzato!\")\n",
    "\n",
    "# Verifica\n",
    "train_count = len(list((dataset_path / \"train\" / \"images\").glob(\"*.jpg\")))\n",
    "test_count = len(list((dataset_path / \"test\" / \"images\").glob(\"*.jpg\")))\n",
    "print(f\"\\nüìä Training images: {train_count}\")\n",
    "print(f\"üìä Test images: {test_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f96f7a0",
   "metadata": {},
   "source": [
    "## üìÅ Step 6: Setup Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf84fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea directory per output\n",
    "directories = ['models', 'checkpoints', 'predictions', 'runs']\n",
    "\n",
    "for dir_name in directories:\n",
    "    dir_path = PROJECT_DIR / dir_name\n",
    "    dir_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Directory create!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b499cb",
   "metadata": {},
   "source": [
    "## üöÄ Step 7: TRAINING (50 Epoche)\n",
    "\n",
    "**Questo richieder√† ~2-3 ore con GPU**\n",
    "\n",
    "Verr√† eseguito `train_cloud.py` che include:\n",
    "- Autoencoder convoluzionale\n",
    "- MSE Loss per ricostruzione\n",
    "- Checkpoints automatici ogni 5 epoche\n",
    "- Resume automatico se interrotto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75233743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training completo\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "!python train_cloud.py --resume\n",
    "\n",
    "print(\"\\n‚úÖ Training completato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e22f4",
   "metadata": {},
   "source": [
    "## üîÆ Step 8: INFERENCE\n",
    "\n",
    "Genera maschere di predizione per tutte le immagini test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e85cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference - genera maschere predette\n",
    "print(\"üîÆ Running inference...\")\n",
    "!python inference.py\n",
    "print(\"\\n‚úÖ Inference completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8316b54",
   "metadata": {},
   "source": [
    "## üìä Step 9: EVALUATION\n",
    "\n",
    "Calcola metriche IoU, Dice, F1-score e ottimizza threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation - calcola metriche\n",
    "print(\"üìä Running evaluation...\")\n",
    "!python evaluate.py\n",
    "print(\"\\n‚úÖ Evaluation completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33648e83",
   "metadata": {},
   "source": [
    "## ‚úÖ COMPLETATO!\n",
    "\n",
    "### üìÅ Risultati disponibili in:\n",
    "\n",
    "- **Modello addestrato**: `models/best_autoencoder.pth`\n",
    "- **Maschere predette**: `predictions/*.jpg`\n",
    "- **Visualizzazioni**: `results_visualization.png`, `threshold_optimization.png`\n",
    "\n",
    "### üíæ Per scaricare i risultati:\n",
    "\n",
    "#### Su Google Colab:\n",
    "```python\n",
    "from google.colab import files\n",
    "files.download('models/best_autoencoder.pth')\n",
    "```\n",
    "\n",
    "#### Su Jupyter locale:\n",
    "I file sono gi√† nella directory del progetto!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda9522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra summary risultati\n",
    "print(\"=\"*60)\n",
    "print(\"üìä SUMMARY FINALE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Model size\n",
    "model_path = PROJECT_DIR / \"models\" / \"best_autoencoder.pth\"\n",
    "if model_path.exists():\n",
    "    size_mb = model_path.stat().st_size / 1024 / 1024\n",
    "    print(f\"\\n‚úÖ Modello: {size_mb:.2f} MB\")\n",
    "\n",
    "# Predictions count\n",
    "predictions = list((PROJECT_DIR / \"predictions\").glob(\"*.jpg\"))\n",
    "print(f\"‚úÖ Predizioni generate: {len(predictions)}\")\n",
    "\n",
    "# Visualizations\n",
    "viz_files = list(PROJECT_DIR.glob(\"*.png\"))\n",
    "print(f\"‚úÖ Visualizzazioni: {len(viz_files)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ TUTTO COMPLETATO!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
